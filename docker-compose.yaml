version: "3.9"

services:
  mongo:
    image: mongo:7
    container_name: spiderdb-mongo
    restart: unless-stopped
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_ROOT_USER:-admin}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_ROOT_PASS:-adminpass}
    volumes:
      - mongo_data:/data/db

  mongo-express:
    image: mongo-express:1
    container_name: spiderdb-me
    restart: unless-stopped
    depends_on:
      - mongo
    ports:
      - "8081:8081"
    environment:
      ME_CONFIG_MONGODB_SERVER: mongo
      ME_CONFIG_MONGODB_ENABLE_ADMIN: "true"
      ME_CONFIG_MONGODB_ADMINUSERNAME: ${MONGO_ROOT_USER:-admin}
      ME_CONFIG_MONGODB_ADMINPASSWORD: ${MONGO_ROOT_PASS:-adminpass}

  scraper:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: spiderdb-scraper
    depends_on:
      - mongo
    # live-edit your code without rebuilding
    volumes:
      - .:/app
    working_dir: /app/books
    environment:
      # if your pipeline needs auth, use: mongodb://admin:adminpass@mongo:27017/?authSource=admin
      MONGODB_URI: mongodb://mongo:27017
      MONGODB_DB: spiderdb
    command: ["scrapy", "crawl", "book"]  # <-- your spider module is books/spiders/book.py

volumes:
  mongo_data: